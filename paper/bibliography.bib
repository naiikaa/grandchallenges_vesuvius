@misc{EduceLab,
      title={EduceLab-Scrolls: Verifiable Recovery of Text from Herculaneum Papyri using X-ray CT}, 
      author={Stephen Parsons and C. Seth Parker and Christy Chapman and Mami Hayashida and W. Brent Seales},
      year={2024},
      eprint={2304.02084},
      archivePrefix={arXiv},
      primaryClass={cs.CV},
      url={https://arxiv.org/abs/2304.02084}, 
}

@misc{vesuvius,
    key = {Vesuvius Homepage},
    note ={Homepage of the Vesuvius Challenge},
    url = {https://scrollprize.org/}
}

@misc{ho_denoising_2020,
	title = {Denoising Diffusion Probabilistic Models},
	url = {http://arxiv.org/abs/2006.11239},
	abstract = {We present high quality image synthesis results using diffusion probabilistic models, a class of latent variable models inspired by considerations from nonequilibrium thermodynamics. Our best results are obtained by training on a weighted variational bound designed according to a novel connection between diffusion probabilistic models and denoising score matching with Langevin dynamics, and our models naturally admit a progressive lossy decompression scheme that can be interpreted as a generalization of autoregressive decoding. On the unconditional {CIFAR}10 dataset, we obtain an Inception score of 9.46 and a state-of-the-art {FID} score of 3.17. On 256x256 {LSUN}, we obtain sample quality similar to {ProgressiveGAN}. Our implementation is available at https://github.com/hojonathanho/diffusion},
	number = {{arXiv}:2006.11239},
	publisher = {{arXiv}},
	author = {Ho, Jonathan and Jain, Ajay and Abbeel, Pieter},
	urldate = {2022-07-13},
	date = {2020-12-16},
	eprinttype = {arxiv},
	eprint = {2006.11239 [cs, stat]},
	keywords = {Computer Science - Machine Learning, Statistics - Machine Learning},
	file = {arXiv Fulltext PDF:C\:\\Users\\Nikita\\Zotero\\storage\\PSRWVEKS\\Ho et al. - 2020 - Denoising Diffusion Probabilistic Models.pdf:application/pdf;arXiv.org Snapshot:C\:\\Users\\Nikita\\Zotero\\storage\\URZX7752\\2006.html:text/html},
}
@misc{nichol_improved_2021,
	title = {Improved Denoising Diffusion Probabilistic Models},
	url = {http://arxiv.org/abs/2102.09672},
	abstract = {Denoising diffusion probabilistic models ({DDPM}) are a class of generative models which have recently been shown to produce excellent samples. We show that with a few simple modifications, {DDPMs} can also achieve competitive log-likelihoods while maintaining high sample quality. Additionally, we find that learning variances of the reverse diffusion process allows sampling with an order of magnitude fewer forward passes with a negligible difference in sample quality, which is important for the practical deployment of these models. We additionally use precision and recall to compare how well {DDPMs} and {GANs} cover the target distribution. Finally, we show that the sample quality and likelihood of these models scale smoothly with model capacity and training compute, making them easily scalable. We release our code at https://github.com/openai/improved-diffusion},
	number = {{arXiv}:2102.09672},
	publisher = {{arXiv}},
	author = {Nichol, Alex and Dhariwal, Prafulla},
	urldate = {2022-07-13},
	date = {2021-02-18},
	eprinttype = {arxiv},
	eprint = {2102.09672 [cs, stat]},
	keywords = {Computer Science - Artificial Intelligence, Computer Science - Machine Learning, Statistics - Machine Learning},
	file = {arXiv Fulltext PDF:C\:\\Users\\Nikita\\Zotero\\storage\\FVFK52XL\\Nichol und Dhariwal - 2021 - Improved Denoising Diffusion Probabilistic Models.pdf:application/pdf;arXiv.org Snapshot:C\:\\Users\\Nikita\\Zotero\\storage\\QHNRSCAR\\2102.html:text/html},
}

@misc{dhariwal_diffusion_2021,
	title = {Diffusion Models Beat {GANs} on Image Synthesis},
	url = {http://arxiv.org/abs/2105.05233},
	abstract = {We show that diffusion models can achieve image sample quality superior to the current state-of-the-art generative models. We achieve this on unconditional image synthesis by finding a better architecture through a series of ablations. For conditional image synthesis, we further improve sample quality with classifier guidance: a simple, compute-efficient method for trading off diversity for fidelity using gradients from a classifier. We achieve an {FID} of 2.97 on {ImageNet} 128\${\textbackslash}times\$128, 4.59 on {ImageNet} 256\${\textbackslash}times\$256, and 7.72 on {ImageNet} 512\${\textbackslash}times\$512, and we match {BigGAN}-deep even with as few as 25 forward passes per sample, all while maintaining better coverage of the distribution. Finally, we find that classifier guidance combines well with upsampling diffusion models, further improving {FID} to 3.94 on {ImageNet} 256\${\textbackslash}times\$256 and 3.85 on {ImageNet} 512\${\textbackslash}times\$512. We release our code at https://github.com/openai/guided-diffusion},
	number = {{arXiv}:2105.05233},
	publisher = {{arXiv}},
	author = {Dhariwal, Prafulla and Nichol, Alex},
	urldate = {2022-07-13},
	date = {2021-06-01},
	eprinttype = {arxiv},
	eprint = {2105.05233 [cs, stat]},
	keywords = {Computer Science - Artificial Intelligence, Computer Science - Computer Vision and Pattern Recognition, Computer Science - Machine Learning, Statistics - Machine Learning},
}